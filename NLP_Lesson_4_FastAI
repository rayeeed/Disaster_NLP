{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":17777,"databundleVersionId":869809,"sourceType":"competition"}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"raw","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import os\niskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')","metadata":{"execution":{"iopub.status.busy":"2024-05-18T23:41:05.992713Z","iopub.execute_input":"2024-05-18T23:41:05.993390Z","iopub.status.idle":"2024-05-18T23:41:05.997853Z","shell.execute_reply.started":"2024-05-18T23:41:05.993355Z","shell.execute_reply":"2024-05-18T23:41:05.996709Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import shutil\nshutil.rmtree(\"/kaggle/working/results\")","metadata":{"execution":{"iopub.status.busy":"2024-05-18T23:40:49.250169Z","iopub.execute_input":"2024-05-18T23:40:49.250531Z","iopub.status.idle":"2024-05-18T23:40:50.720335Z","shell.execute_reply.started":"2024-05-18T23:40:49.250504Z","shell.execute_reply":"2024-05-18T23:40:50.718542Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# for working with paths in Python, I recommend using `pathlib.Path`\nfrom pathlib import Path\n\nif iskaggle:\n    path = Path('/kaggle/input/nlp-getting-started')\n    ! pip install -q datasets","metadata":{"execution":{"iopub.status.busy":"2024-05-18T23:41:10.049025Z","iopub.execute_input":"2024-05-18T23:41:10.049688Z","iopub.status.idle":"2024-05-18T23:41:22.290907Z","shell.execute_reply.started":"2024-05-18T23:41:10.049652Z","shell.execute_reply":"2024-05-18T23:41:22.289602Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv('/kaggle/input/nlp-getting-started/train.csv')","metadata":{"execution":{"iopub.status.busy":"2024-05-18T23:41:22.293547Z","iopub.execute_input":"2024-05-18T23:41:22.294283Z","iopub.status.idle":"2024-05-18T23:41:22.681709Z","shell.execute_reply.started":"2024-05-18T23:41:22.294241Z","shell.execute_reply":"2024-05-18T23:41:22.680665Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df.describe(include='object')","metadata":{"execution":{"iopub.status.busy":"2024-05-18T23:41:22.683008Z","iopub.execute_input":"2024-05-18T23:41:22.683313Z","iopub.status.idle":"2024-05-18T23:41:22.712522Z","shell.execute_reply.started":"2024-05-18T23:41:22.683287Z","shell.execute_reply":"2024-05-18T23:41:22.711515Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"           keyword location                                               text\ncount         7552     5080                                               7613\nunique         221     3341                                               7503\ntop     fatalities      USA  11-Year-Old Boy Charged With Manslaughter of T...\nfreq            45      104                                                 10","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>7552</td>\n      <td>5080</td>\n      <td>7613</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>221</td>\n      <td>3341</td>\n      <td>7503</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>fatalities</td>\n      <td>USA</td>\n      <td>11-Year-Old Boy Charged With Manslaughter of T...</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>45</td>\n      <td>104</td>\n      <td>10</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.tail()","metadata":{"execution":{"iopub.status.busy":"2024-05-18T23:41:22.715313Z","iopub.execute_input":"2024-05-18T23:41:22.718244Z","iopub.status.idle":"2024-05-18T23:41:22.731562Z","shell.execute_reply.started":"2024-05-18T23:41:22.718207Z","shell.execute_reply":"2024-05-18T23:41:22.730433Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"         id keyword location  \\\n7608  10869     NaN      NaN   \n7609  10870     NaN      NaN   \n7610  10871     NaN      NaN   \n7611  10872     NaN      NaN   \n7612  10873     NaN      NaN   \n\n                                                   text  target  \n7608  Two giant cranes holding a bridge collapse int...       1  \n7609  @aria_ahrary @TheTawniest The out of control w...       1  \n7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  \n7611  Police investigating after an e-bike collided ...       1  \n7612  The Latest: More Homes Razed by Northern Calif...       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7608</th>\n      <td>10869</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Two giant cranes holding a bridge collapse int...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7609</th>\n      <td>10870</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7610</th>\n      <td>10871</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7611</th>\n      <td>10872</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>Police investigating after an e-bike collided ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7612</th>\n      <td>10873</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>The Latest: More Homes Razed by Northern Calif...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from datasets import Dataset,DatasetDict\n\nds = Dataset.from_pandas(df)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T23:41:22.732886Z","iopub.execute_input":"2024-05-18T23:41:22.733221Z","iopub.status.idle":"2024-05-18T23:41:23.485760Z","shell.execute_reply.started":"2024-05-18T23:41:22.733191Z","shell.execute_reply":"2024-05-18T23:41:23.484979Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"ds = ds.rename_columns({'target':'labels','text':'input'})","metadata":{"execution":{"iopub.status.busy":"2024-05-18T23:41:23.486808Z","iopub.execute_input":"2024-05-18T23:41:23.487212Z","iopub.status.idle":"2024-05-18T23:41:23.494492Z","shell.execute_reply.started":"2024-05-18T23:41:23.487186Z","shell.execute_reply":"2024-05-18T23:41:23.493466Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model_nm = 'microsoft/deberta-v3-small'","metadata":{"execution":{"iopub.status.busy":"2024-05-18T23:41:23.495568Z","iopub.execute_input":"2024-05-18T23:41:23.495871Z","iopub.status.idle":"2024-05-18T23:41:23.506921Z","shell.execute_reply.started":"2024-05-18T23:41:23.495834Z","shell.execute_reply":"2024-05-18T23:41:23.506064Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForSequenceClassification,AutoTokenizer\ntokz = AutoTokenizer.from_pretrained(model_nm)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T23:41:23.508049Z","iopub.execute_input":"2024-05-18T23:41:23.508326Z","iopub.status.idle":"2024-05-18T23:41:27.196718Z","shell.execute_reply.started":"2024-05-18T23:41:23.508303Z","shell.execute_reply":"2024-05-18T23:41:27.195606Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:550: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"ds","metadata":{"execution":{"iopub.status.busy":"2024-05-18T23:41:27.197929Z","iopub.execute_input":"2024-05-18T23:41:27.198389Z","iopub.status.idle":"2024-05-18T23:41:27.204570Z","shell.execute_reply.started":"2024-05-18T23:41:27.198362Z","shell.execute_reply":"2024-05-18T23:41:27.203607Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['id', 'keyword', 'location', 'input', 'labels'],\n    num_rows: 7613\n})"},"metadata":{}}]},{"cell_type":"code","source":"def tok_func(x): return tokz(x[\"input\"])","metadata":{"execution":{"iopub.status.busy":"2024-05-18T23:41:27.207429Z","iopub.execute_input":"2024-05-18T23:41:27.207816Z","iopub.status.idle":"2024-05-18T23:41:27.215751Z","shell.execute_reply.started":"2024-05-18T23:41:27.207770Z","shell.execute_reply":"2024-05-18T23:41:27.214839Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"tok_ds = ds.map(tok_func, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T23:41:27.216757Z","iopub.execute_input":"2024-05-18T23:41:27.217057Z","iopub.status.idle":"2024-05-18T23:41:27.941473Z","shell.execute_reply.started":"2024-05-18T23:41:27.217035Z","shell.execute_reply":"2024-05-18T23:41:27.940472Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/7613 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f96330b5599456f847f450363446909"}},"metadata":{}}]},{"cell_type":"code","source":"row = tok_ds[0]\nrow['input'], row['input_ids']","metadata":{"execution":{"iopub.status.busy":"2024-05-18T23:41:27.943101Z","iopub.execute_input":"2024-05-18T23:41:27.943453Z","iopub.status.idle":"2024-05-18T23:41:27.951875Z","shell.execute_reply.started":"2024-05-18T23:41:27.943412Z","shell.execute_reply":"2024-05-18T23:41:27.950831Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"('Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all',\n [1,\n  581,\n  65453,\n  281,\n  262,\n  18037,\n  265,\n  291,\n  953,\n  117831,\n  903,\n  4924,\n  17018,\n  43632,\n  381,\n  305,\n  2])"},"metadata":{}}]},{"cell_type":"code","source":"tokz.vocab[\"'\"]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eval_df = pd.read_csv(path/'test.csv')\neval_df.describe(include='object')","metadata":{"execution":{"iopub.status.busy":"2024-05-18T23:41:27.953633Z","iopub.execute_input":"2024-05-18T23:41:27.954183Z","iopub.status.idle":"2024-05-18T23:41:27.990129Z","shell.execute_reply.started":"2024-05-18T23:41:27.954152Z","shell.execute_reply":"2024-05-18T23:41:27.989077Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"        keyword  location                                               text\ncount      3237      2158                                               3263\nunique      221      1602                                               3243\ntop     deluged  New York  11-Year-Old Boy Charged With Manslaughter of T...\nfreq         23        38                                                  3","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>3237</td>\n      <td>2158</td>\n      <td>3263</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>221</td>\n      <td>1602</td>\n      <td>3243</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>deluged</td>\n      <td>New York</td>\n      <td>11-Year-Old Boy Charged With Manslaughter of T...</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>23</td>\n      <td>38</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"len(eval_df)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T23:41:28.888621Z","iopub.execute_input":"2024-05-18T23:41:28.889417Z","iopub.status.idle":"2024-05-18T23:41:28.895386Z","shell.execute_reply.started":"2024-05-18T23:41:28.889380Z","shell.execute_reply":"2024-05-18T23:41:28.894357Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"3263"},"metadata":{}}]},{"cell_type":"code","source":"dds = tok_ds.train_test_split(0.25, seed=42)\ndds","metadata":{"execution":{"iopub.status.busy":"2024-05-18T23:41:32.815298Z","iopub.execute_input":"2024-05-18T23:41:32.816170Z","iopub.status.idle":"2024-05-18T23:41:32.833974Z","shell.execute_reply.started":"2024-05-18T23:41:32.816134Z","shell.execute_reply":"2024-05-18T23:41:32.833002Z"},"trusted":true},"execution_count":17,"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['id', 'keyword', 'location', 'input', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 5709\n    })\n    test: Dataset({\n        features: ['id', 'keyword', 'location', 'input', 'labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 1904\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"eval_ds = Dataset.from_pandas(eval_df)\neval_ds = eval_ds.rename_columns({'text':'input'})\neval_ds=eval_ds.map(tok_func, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T23:41:38.479511Z","iopub.execute_input":"2024-05-18T23:41:38.480237Z","iopub.status.idle":"2024-05-18T23:41:38.765747Z","shell.execute_reply.started":"2024-05-18T23:41:38.480203Z","shell.execute_reply":"2024-05-18T23:41:38.764559Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/3263 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f1c894f800b84f2881ca8cdae60a32cc"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import TrainingArguments,Trainer","metadata":{"execution":{"iopub.status.busy":"2024-05-18T23:41:57.014223Z","iopub.execute_input":"2024-05-18T23:41:57.015023Z","iopub.status.idle":"2024-05-18T23:42:00.429016Z","shell.execute_reply.started":"2024-05-18T23:41:57.014988Z","shell.execute_reply":"2024-05-18T23:42:00.428166Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"2024-05-18 23:41:58.556745: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-18 23:41:58.556820: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-18 23:41:58.558181: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"bs = 128\nepochs = 4","metadata":{"execution":{"iopub.status.busy":"2024-05-18T23:42:00.430493Z","iopub.execute_input":"2024-05-18T23:42:00.431054Z","iopub.status.idle":"2024-05-18T23:42:00.435917Z","shell.execute_reply.started":"2024-05-18T23:42:00.431025Z","shell.execute_reply":"2024-05-18T23:42:00.434835Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"lr = 8e-5","metadata":{"execution":{"iopub.status.busy":"2024-05-18T23:42:01.778931Z","iopub.execute_input":"2024-05-18T23:42:01.779305Z","iopub.status.idle":"2024-05-18T23:42:01.783902Z","shell.execute_reply.started":"2024-05-18T23:42:01.779275Z","shell.execute_reply":"2024-05-18T23:42:01.782732Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"args = TrainingArguments('outputs', learning_rate=lr, warmup_ratio=0.1, lr_scheduler_type='cosine', fp16=True,\n    evaluation_strategy=\"epoch\", per_device_train_batch_size=bs, per_device_eval_batch_size=bs*2,\n    num_train_epochs=epochs, weight_decay=0.01, report_to='none')","metadata":{"execution":{"iopub.status.busy":"2024-05-18T23:42:02.299507Z","iopub.execute_input":"2024-05-18T23:42:02.299974Z","iopub.status.idle":"2024-05-18T23:42:02.406763Z","shell.execute_reply.started":"2024-05-18T23:42:02.299937Z","shell.execute_reply":"2024-05-18T23:42:02.405781Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"!pip install scikit-learn\nfrom sklearn.metrics import f1_score\n\ndef f1_d(eval_pred):\n    logits, labels = eval_pred\n    predictions = logits.argmax(axis=-1)  # Convert logits to predictions\n    f1 = f1_score(labels, predictions, average='weighted')  # Calculate F1 score\n    return {'f1': f1}\n","metadata":{"execution":{"iopub.status.busy":"2024-05-18T23:45:25.928412Z","iopub.execute_input":"2024-05-18T23:45:25.929266Z","iopub.status.idle":"2024-05-18T23:45:38.250832Z","shell.execute_reply.started":"2024-05-18T23:45:25.929229Z","shell.execute_reply":"2024-05-18T23:45:38.249623Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.2.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"def corr_d(eval_pred): return {'pearson': corr(*eval_pred)}","metadata":{"execution":{"iopub.status.busy":"2024-05-18T23:42:17.049719Z","iopub.execute_input":"2024-05-18T23:42:17.050041Z","iopub.status.idle":"2024-05-18T23:42:17.055140Z","shell.execute_reply.started":"2024-05-18T23:42:17.050010Z","shell.execute_reply":"2024-05-18T23:42:17.054207Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"model = AutoModelForSequenceClassification.from_pretrained(model_nm, num_labels=1)\ntrainer = Trainer(model, args, train_dataset=dds['train'], eval_dataset=dds['test'],\n                  tokenizer=tokz, compute_metrics=corr_d)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T23:43:28.020329Z","iopub.execute_input":"2024-05-18T23:43:28.020701Z","iopub.status.idle":"2024-05-18T23:43:29.476551Z","shell.execute_reply.started":"2024-05-18T23:43:28.020673Z","shell.execute_reply":"2024-05-18T23:43:29.475731Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nSome weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer.train();\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> **Regression Problem****","metadata":{}},{"cell_type":"code","source":"from transformers import DataCollatorWithPadding, Trainer, TrainingArguments\nimport torch\n\nclass CustomDataCollatorWithPadding(DataCollatorWithPadding):\n    def __call__(self, features):\n        batch = super().__call__(features)\n        if 'labels' in batch:\n            batch['labels'] = batch['labels'].float()\n        return batch\n\n# Instantiate the custom data collator with your tokenizer\ndata_collator = CustomDataCollatorWithPadding(tokz)\n\ntraining_args = TrainingArguments(\n    output_dir='./results',          # output directory\n    num_train_epochs=3,              # total number of training epochs\n    per_device_train_batch_size=8,   # batch size for training\n    per_device_eval_batch_size=8,    # batch size for evaluation\n    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n    weight_decay=0.01,         # directory for storing logs\n    report_to=\"none\"\n)\n\ntrainer = Trainer(\n    model=model,                     \n    args=training_args,              \n    train_dataset=dds['train'],     \n    eval_dataset=dds['test'],       \n    compute_metrics=f1_d,            \n    data_collator=data_collator,  # use the custom data collator\n)\n\ntrainer.train()\n","metadata":{"execution":{"iopub.status.busy":"2024-05-18T23:49:17.925923Z","iopub.execute_input":"2024-05-18T23:49:17.926598Z","iopub.status.idle":"2024-05-18T23:53:38.106687Z","shell.execute_reply.started":"2024-05-18T23:49:17.926563Z","shell.execute_reply":"2024-05-18T23:53:38.105722Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1071' max='1071' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1071/1071 04:19, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.182000</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.105300</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1071, training_loss=0.13942101155342507, metrics={'train_runtime': 259.7662, 'train_samples_per_second': 65.932, 'train_steps_per_second': 4.123, 'total_flos': 240796896933120.0, 'train_loss': 0.13942101155342507, 'epoch': 3.0})"},"metadata":{}}]},{"cell_type":"code","source":"from transformers import DataCollatorWithPadding, Trainer, TrainingArguments\nimport torch\n\nclass CustomDataCollatorWithPadding(DataCollatorWithPadding):\n    def __call__(self, features):\n        batch = super().__call__(features)\n        if 'labels' in batch:\n            batch['labels'] = batch['labels'].float()\n        return batch\n\n# Instantiate the custom data collator with your tokenizer\ndata_collator = CustomDataCollatorWithPadding(tokz)\n# Define the training arguments\ntraining_args = TrainingArguments(\n    output_dir='./results',          \n    num_train_epochs=3,            \n    per_device_train_batch_size=8,   \n    per_device_eval_batch_size=8,    \n    warmup_steps=500,                \n    weight_decay=0.01,              \n    logging_dir='./logs',            \n    report_to=\"none\",\n    evaluation_strategy=\"epoch\"     # Evaluate at the end of each epoch\n)\n\n# Instantiate Trainer\ntrainer = Trainer(\n    model=model,                     \n    args=training_args,              \n    train_dataset=dds['train'],     \n    eval_dataset=dds['test'],       \n    compute_metrics=f1_d,            \n    data_collator=data_collator,\n)\n\n# Make predictions\npredictions = trainer.predict(dds['test']).predictions\n\n# Convert predictions to binary integers (0 or 1)\npreds = (predictions > 0.5).astype(int)\n\n# Ensure preds is a 1D array if necessary\npreds = preds.flatten()\n\n# Extract 'id' values from eval_ds\nids = dds['test']['id']\n\n# Save the predictions to a submission.csv file\nsubmission_df = pd.DataFrame({'id': ids, 'target': preds})\nsubmission_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-18T23:47:08.277716Z","iopub.execute_input":"2024-05-18T23:47:08.278655Z","iopub.status.idle":"2024-05-18T23:47:22.261040Z","shell.execute_reply.started":"2024-05-18T23:47:08.278620Z","shell.execute_reply":"2024-05-18T23:47:22.259465Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='119' max='119' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [119/119 00:09]\n    </div>\n    "},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[31], line 37\u001b[0m\n\u001b[1;32m     27\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     28\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,                     \n\u001b[1;32m     29\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,              \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mdata_collator,\n\u001b[1;32m     34\u001b[0m )\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdds\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mpredictions\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Convert predictions to binary integers (0 or 1)\u001b[39;00m\n\u001b[1;32m     40\u001b[0m preds \u001b[38;5;241m=\u001b[39m (predictions \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3441\u001b[0m, in \u001b[0;36mTrainer.predict\u001b[0;34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3438\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3440\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3441\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3442\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPrediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\n\u001b[1;32m   3443\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3444\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3445\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3656\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3652\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_metrics(\n\u001b[1;32m   3653\u001b[0m             EvalPrediction(predictions\u001b[38;5;241m=\u001b[39mall_preds, label_ids\u001b[38;5;241m=\u001b[39mall_labels, inputs\u001b[38;5;241m=\u001b[39mall_inputs)\n\u001b[1;32m   3654\u001b[0m         )\n\u001b[1;32m   3655\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3656\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEvalPrediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_preds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3657\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3658\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m {}\n","Cell \u001b[0;32mIn[28], line 7\u001b[0m, in \u001b[0;36mf1_d\u001b[0;34m(eval_pred)\u001b[0m\n\u001b[1;32m      5\u001b[0m logits, labels \u001b[38;5;241m=\u001b[39m eval_pred\n\u001b[1;32m      6\u001b[0m predictions \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39margmax(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Convert logits to predictions\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m f1 \u001b[38;5;241m=\u001b[39m \u001b[43mf1_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweighted\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calculate F1 score\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m'\u001b[39m: f1}\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1146\u001b[0m, in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mf1_score\u001b[39m(\n\u001b[1;32m   1012\u001b[0m     y_true,\n\u001b[1;32m   1013\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1019\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1020\u001b[0m ):\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure.\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \n\u001b[1;32m   1023\u001b[0m \u001b[38;5;124;03m    The F1 score can be interpreted as a harmonic mean of the precision and\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1144\u001b[0m \u001b[38;5;124;03m    array([0.66666667, 1.        , 0.66666667])\u001b[39;00m\n\u001b[1;32m   1145\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfbeta_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1147\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1152\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1153\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1287\u001b[0m, in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1158\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfbeta_score\u001b[39m(\n\u001b[1;32m   1159\u001b[0m     y_true,\n\u001b[1;32m   1160\u001b[0m     y_pred,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1167\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1168\u001b[0m ):\n\u001b[1;32m   1169\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the F-beta score.\u001b[39;00m\n\u001b[1;32m   1170\u001b[0m \n\u001b[1;32m   1171\u001b[0m \u001b[38;5;124;03m    The F-beta score is the weighted harmonic mean of precision and recall,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1284\u001b[0m \u001b[38;5;124;03m    array([0.71..., 0.        , 0.        ])\u001b[39;00m\n\u001b[1;32m   1285\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1287\u001b[0m     _, _, f, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1289\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1291\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mf-score\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1295\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1298\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1573\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1571\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m beta \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1572\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeta should be >=0 in the F-beta score\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1573\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43m_check_set_wise_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1575\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[1;32m   1576\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1374\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m average \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m average_options \u001b[38;5;129;01mand\u001b[39;00m average \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1372\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage has to be one of \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(average_options))\n\u001b[0;32m-> 1374\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;66;03m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[1;32m   1376\u001b[0m \u001b[38;5;66;03m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[1;32m   1377\u001b[0m present_labels \u001b[38;5;241m=\u001b[39m unique_labels(y_true, y_pred)\u001b[38;5;241m.\u001b[39mtolist()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:86\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[1;32m     60\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     61\u001b[0m \n\u001b[1;32m     62\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 86\u001b[0m     \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     88\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:394\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_consistent_length\u001b[39m(\u001b[38;5;241m*\u001b[39marrays):\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that all arrays have consistent first dimensions.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Checks whether all objects in arrays have the same shape or length.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;124;03m        Objects that will be checked for consistent length.\u001b[39;00m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 394\u001b[0m     lengths \u001b[38;5;241m=\u001b[39m [_num_samples(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m arrays \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    395\u001b[0m     uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:394\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_consistent_length\u001b[39m(\u001b[38;5;241m*\u001b[39marrays):\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that all arrays have consistent first dimensions.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Checks whether all objects in arrays have the same shape or length.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;124;03m        Objects that will be checked for consistent length.\u001b[39;00m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 394\u001b[0m     lengths \u001b[38;5;241m=\u001b[39m [\u001b[43m_num_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m arrays \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    395\u001b[0m     uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:335\u001b[0m, in \u001b[0;36m_num_samples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    334\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 335\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    336\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSingleton array \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m cannot be considered a valid collection.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m x\n\u001b[1;32m    337\u001b[0m         )\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;66;03m# Check that shape is returning an integer or default to len\u001b[39;00m\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;66;03m# Dask dataframes may not return numeric shape[0] value\u001b[39;00m\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], numbers\u001b[38;5;241m.\u001b[39mIntegral):\n","\u001b[0;31mTypeError\u001b[0m: Singleton array 62 cannot be considered a valid collection."],"ename":"TypeError","evalue":"Singleton array 62 cannot be considered a valid collection.","output_type":"error"}]},{"cell_type":"code","source":"# Make predictions\npredictions = trainer.predict(eval_ds).predictions\n\n# Convert predictions to binary integers (0 or 1)\npreds = (predictions > 0.5).astype(int)\n\n# Ensure preds is a 1D array if necessary\npreds = preds.flatten()\n\n# Extract 'id' values from eval_ds\nids = eval_ds['id']\n\n# Save the predictions to a submission.csv file\nsubmission_df = pd.DataFrame({'id': ids, 'target': preds})\nsubmission_df.to_csv('submission.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-18T23:54:51.770807Z","iopub.execute_input":"2024-05-18T23:54:51.771785Z","iopub.status.idle":"2024-05-18T23:55:08.447051Z","shell.execute_reply.started":"2024-05-18T23:54:51.771726Z","shell.execute_reply":"2024-05-18T23:55:08.446236Z"},"trusted":true},"execution_count":39,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}]},{"cell_type":"code","source":"# Save the predictions to a submission.csv file\nsubmission_df = pd.DataFrame({'id': range(len(preds)), 'target': preds})\nsubmission_df.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dds['train']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df['id'].dtype()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}